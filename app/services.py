"""
======================================
ä¸šåŠ¡é€»è¾‘å±‚ï¼ˆService Layerï¼‰
======================================

è¿™ä¸ªæ–‡ä»¶å°è£…äº†æ‰€æœ‰ä¸šåŠ¡é€»è¾‘ï¼š
- LLM è°ƒç”¨
- é™æµæ£€æŸ¥
- CarePlan åˆ›å»ºå’Œè§¦å‘å¼‚æ­¥ä»»åŠ¡
- ç»Ÿè®¡æ•°æ®æŸ¥è¯¢
"""

import os
import time
from datetime import datetime
from django.core.cache import cache


# ============================================
# é™æµæœåŠ¡
# ============================================
def check_rate_limit():
    """
    æ£€æŸ¥ API è°ƒç”¨é¢‘ç‡é™åˆ¶ï¼ˆä» views.py è¿ç§»ï¼‰
    
    è¿”å›:
        (allowed, error_msg) - æ˜¯å¦å…è®¸ï¼Œé”™è¯¯ä¿¡æ¯
    """
    print("   ğŸŸ¢ services.py â†’ check_rate_limit() æ‰§è¡Œä¸­...")
    
    now = datetime.now()
    
    # æ£€æŸ¥æ¯åˆ†é’Ÿé™åˆ¶
    minute_key = f"gemini_calls_{now.strftime('%Y%m%d%H%M')}"
    minute_count = cache.get(minute_key, 0)
    print(f"   å½“å‰åˆ†é’Ÿè¯·æ±‚æ•°: {minute_count}/15")
    
    if minute_count >= 15:
        return False, "Too many requests per minute. Please wait."
    
    # æ£€æŸ¥æ¯å¤©é™åˆ¶
    day_key = f"gemini_calls_{now.strftime('%Y%m%d')}"
    day_count = cache.get(day_key, 0)
    print(f"   å½“å‰æ¯æ—¥è¯·æ±‚æ•°: {day_count}/1500")
    
    if day_count >= 1500:
        return False, "Daily quota exceeded. Please try tomorrow."
    
    # æ›´æ–°è®¡æ•°
    cache.set(minute_key, minute_count + 1, timeout=60)
    cache.set(day_key, day_count + 1, timeout=86400)
    
    return True, None


# ============================================
# CarePlan ä¸šåŠ¡é€»è¾‘
# ============================================
def create_careplan(data):
    """
    åˆ›å»º CarePlan å¹¶è§¦å‘å¼‚æ­¥ä»»åŠ¡
    
    æµç¨‹ï¼šProvider â†’ Patient â†’ Order â†’ CarePlan â†’ Celery ä»»åŠ¡
    
    å‚æ•°:
        data: è¯·æ±‚æ•°æ®ï¼ˆrequest.POST æˆ– dictï¼‰
    
    è¿”å›:
        åˆ›å»ºçš„ CarePlan å¯¹è±¡
    """
    print("   ğŸŸ¢ services.py â†’ create_careplan() æ‰§è¡Œä¸­...")
    print(f"   æ¥æ”¶æ•°æ®ç±»å‹: {type(data).__name__}")
    
    from .models import Patient, Provider, Order, CarePlan
    from .tasks import generate_care_plan_task
    
    # 1. æŸ¥æ‰¾æˆ–åˆ›å»º Provider
    print("   ğŸ“ æŸ¥æ‰¾/åˆ›å»º Provider...")
    provider, provider_created = Provider.objects.get_or_create(
        npi=data['referring_provider_npi'],
        defaults={'name': data['referring_provider']}
    )
    print(f"   {'âœ¨ æ–°å»º' if provider_created else 'â™»ï¸ å¤ç”¨'} Provider: {provider}")
    
    # 2. æŸ¥æ‰¾æˆ–åˆ›å»º Patient
    print("   ğŸ“ æŸ¥æ‰¾/åˆ›å»º Patient...")
    patient, patient_created = Patient.objects.get_or_create(
        mrn=data['patient_mrn'],
        defaults={
            'first_name': data['patient_first_name'],
            'last_name': data['patient_last_name'],
            'date_of_birth': data['patient_dob'],
        }
    )
    print(f"   {'âœ¨ æ–°å»º' if patient_created else 'â™»ï¸ å¤ç”¨'} Patient: {patient}")
    
    # 3. åˆ›å»º Order
    print("   ğŸ“ åˆ›å»º Order...")
    order = Order.objects.create(
        patient=patient,
        provider=provider,
        medication_name=data['medication_name'],
        primary_diagnosis=data.get('patient_primary_diagnosis', ''),
        additional_diagnosis=data.get('additional_diagnosis', ''),
        medication_history=data.get('medication_history', ''),
        clinical_notes=data.get('clinical_notes', ''),
    )
    print(f"   âœ… Order åˆ›å»ºæˆåŠŸ: {order}")
    
    # 4. åˆ›å»º CarePlan
    print("   ğŸ“ åˆ›å»º CarePlan...")
    care_plan = CarePlan.objects.create(order=order)
    print(f"   âœ… CarePlan åˆ›å»ºæˆåŠŸ: {care_plan}")
    
    # 5. è§¦å‘å¼‚æ­¥ä»»åŠ¡
    print("   ğŸš€ è§¦å‘ Celery å¼‚æ­¥ä»»åŠ¡...")
    generate_care_plan_task.delay(care_plan.id)
    print("   âœ… ä»»åŠ¡å·²å‘é€åˆ° Redis é˜Ÿåˆ—")
    
    return care_plan


def get_stats_data():
    """
    è·å–ç»Ÿè®¡æ•°æ®ï¼ˆä» views.py è¿ç§»ï¼‰
    
    è¿”å›:
        åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
    """
    from .models import CarePlan
    from careplan.celery import app
    
    # æ•°æ®åº“ç»Ÿè®¡
    total = CarePlan.objects.count()
    pending = CarePlan.objects.filter(status='pending').count()
    processing = CarePlan.objects.filter(status='processing').count()
    completed = CarePlan.objects.filter(status='completed').count()
    failed = CarePlan.objects.filter(status='failed').count()
    
    # Celery é˜Ÿåˆ—ç»Ÿè®¡
    try:
        inspect = app.control.inspect()
        reserved = inspect.reserved() or {}
        active = inspect.active() or {}
        queue_length = sum(len(tasks) for tasks in reserved.values())
        queue_length += sum(len(tasks) for tasks in active.values())
    except Exception:
        queue_length = 0
    
    # æœ€è¿‘è®°å½•
    recent_plans = CarePlan.objects.select_related(
        'order__patient', 'order__provider'
    ).all().order_by('-created_at')[:10]
    
    return {
        'total': total,
        'pending': pending,
        'processing': processing,
        'completed': completed,
        'failed': failed,
        'queue_length': queue_length,
        'recent_plans': recent_plans,
    }


# ============================================
# Mock LLM å‡½æ•°
# ============================================
def get_mock_response(prompt):
    """
    Mock LLM å“åº”å‡½æ•°ï¼Œç”¨äºå¼€å‘å’Œæµ‹è¯•ã€‚
    
    ç‰¹ç‚¹ï¼š
    - ä¸è°ƒç”¨ä»»ä½•å¤–éƒ¨ API
    - è¿”å›å›ºå®šçš„ Care Plan æ¨¡æ¿
    - æ¨¡æ‹Ÿ 2 ç§’å»¶è¿Ÿï¼ˆæ¨¡æ‹ŸçœŸå® API è°ƒç”¨æ—¶é—´ï¼‰
    
    å‚æ•°:
        prompt: æç¤ºè¯ï¼ˆè¿™é‡Œä¸ä¼šä½¿ç”¨ï¼Œä½†ä¿æŒæ¥å£ä¸€è‡´ï¼‰
    
    è¿”å›:
        å›ºå®šçš„ Care Plan æ–‡æœ¬
    """
    print("   ğŸ­ [MOCK] ä½¿ç”¨ Mock LLM å“åº”ï¼ˆéçœŸå® API è°ƒç”¨ï¼‰")
    
    # æ¨¡æ‹Ÿ API å»¶è¿Ÿ
    time.sleep(5)
    
    mock_care_plan = """
=====================================
SPECIALTY PHARMACY CARE PLAN (MOCK)
=====================================

ğŸ“‹ PROBLEM LIST / DRUG THERAPY PROBLEMS (DTPs)
----------------------------------------------
1. High-cost specialty medication requiring prior authorization
2. Potential adherence challenges due to complex dosing schedule
3. Need for patient education on self-administration
4. Risk of adverse effects requiring monitoring

ğŸ¯ SMART GOALS
--------------
1. Patient will demonstrate proper self-injection technique within 2 weeks
2. Achieve 90%+ medication adherence over 3 months
3. Complete all required lab monitoring as scheduled
4. Report any adverse effects within 24 hours

ğŸ’Š PHARMACIST INTERVENTIONS/PLAN
---------------------------------
1. Initial Consultation:
   - Review medication therapy and expected outcomes
   - Educate patient on proper storage and handling
   - Demonstrate injection technique with training device

2. Ongoing Support:
   - Monthly adherence check-in calls
   - Coordinate refill timing with insurance
   - Address any side effect concerns

ğŸ“Š MONITORING PLAN & LAB SCHEDULE
----------------------------------
- Baseline: CBC, CMP, LFTs before starting therapy
- Week 2: Follow-up call to assess tolerance
- Month 1: Repeat labs, efficacy assessment
- Month 3: Comprehensive therapy review

=====================================
âš ï¸  THIS IS A MOCK RESPONSE FOR TESTING
    Set USE_MOCK_LLM=false for production
=====================================
"""
    
    return mock_care_plan


# ============================================
# çœŸå® LLM å‡½æ•°ï¼ˆGeminiï¼‰
# ============================================
def get_real_gemini_response(prompt):
    """
    è°ƒç”¨çœŸå®çš„ Gemini APIã€‚
    
    å‚æ•°:
        prompt: æç¤ºè¯
    
    è¿”å›:
        LLM ç”Ÿæˆçš„æ–‡æœ¬
    """
    import google.generativeai as genai
    
    # 1. é…ç½® API Key
    genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
    
    # 2. ç»Ÿä¸€ç®¡ç†æ¨¡å‹åç§°
    model_name = 'gemini-2.5-flash'
    
    model = genai.GenerativeModel(model_name)
    
    # 3. æ‰§è¡Œè°ƒç”¨
    response = model.generate_content(prompt)
    return response.text


# ============================================
# ç»Ÿä¸€å…¥å£å‡½æ•°
# ============================================
def get_gemini_response(prompt):
    """
    ç»Ÿä¸€çš„ LLM è°ƒç”¨å…¥å£ã€‚
    
    æ ¹æ®ç¯å¢ƒå˜é‡ USE_MOCK_LLM å†³å®šä½¿ç”¨ Mock è¿˜æ˜¯çœŸå® APIï¼š
    - USE_MOCK_LLM=true  â†’ ä½¿ç”¨ Mockï¼ˆå¼€å‘/æµ‹è¯•ï¼‰
    - USE_MOCK_LLM=false æˆ–æœªè®¾ç½® â†’ ä½¿ç”¨çœŸå® APIï¼ˆç”Ÿäº§ï¼‰
    
    å‚æ•°:
        prompt: æç¤ºè¯
    
    è¿”å›:
        ç”Ÿæˆçš„ Care Plan æ–‡æœ¬
    """
    use_mock = os.getenv('USE_MOCK_LLM', 'false').lower() == 'true'
    
    if use_mock:
        return get_mock_response(prompt)
    else:
        return get_real_gemini_response(prompt)